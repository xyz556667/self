---
title: "AS10-1：誰是來亂的？"
author: "卓雍然 D994010001"
date: "`r Sys.time()`"
output: 
  html_document:
    highlight: pygments
    theme: flatly
    css: style.css
---

The data for this problem is based on the revision history of the page Language. Wikipedia provides a history for each page that consists of the state of the page at each revision. Rather than manually considering each revision, a script was run that checked whether edits stayed or were reverted. If a change was eventually reverted then that revision is marked as vandalism. This may result in some misclassifications, but the script performs well enough for our needs.

As a result of this preprocessing, some common processing tasks have already been done, including lower-casing and punctuation removal. The columns in the dataset are:

+ Vandal = 1 if this edit was vandalism, 0 if not.
+ Minor = 1 if the user marked this edit as a "minor edit", 0 if not.
+ Loggedin = 1 if the user made this edit while using a Wikipedia account, 0 if they did not.
+ Added = The unique words added.
+ Removed = The unique words removed.

<br><hr>

```{r}
packages = c(
  "dplyr","ggplot2","caTools","tm","SnowballC","ROCR","rpart","rpart.plot","randomForest")
existing = as.character(installed.packages()[,1])
for(pkg in packages[!(packages %in% existing)]) install.packages(pkg)
```

```{r warning=F, message=F, cache=F, error=F}
rm(list=ls(all=TRUE))
Sys.setlocale("LC_ALL","C")
options(digits=5, scipen=10)

library(dplyr)
library(tm)
library(SnowballC)
library(ROCR)
library(caTools)
library(rpart)
library(rpart.plot)
library(randomForest)
```
<br>

### Problem 1 - Bags of Words

##### 1.1 The data set

```{r}
wiki = read.csv("data/wiki.csv", stringsAsFactors = F)
wiki$Vandal = factor(wiki$Vandal)
table(wiki$Vandal)
```

【P1.1】__How many cases of vandalism were detected in the history of this page?__

+ 1815
+

##### 1.2 DTM, The Added Words
```{r}
library(tm)
library(SnowballC)

# Create corpus for Added Words
txt = iconv(wiki$Added, to = "utf-8", sub="")
corpus = Corpus(VectorSource(txt))
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
dtm
```
【P1.2】__How many terms appear in `dtmAdded`?__

+ 6675
+

##### 1.3 Handle Sparsity
Filter out sparse terms by keeping only terms that appear in 0.3% or more of the revisions, and call the new matrix sparseAdded. 
```{r}
nwAdded = rowSums(as.matrix(dtm))     # no. word added in each edit
dtm = removeSparseTerms(dtm, 0.997)
dtm
```
【P1.3】__How many terms appear in `sparseAdded`?__

+ 166
+

##### 1.4 Create Data Frames, `wordAdded` & `wordRemoved`
Convert sparseAdded to a data frame called `wordsAdded`, and then prepend all the words with the letter A, by using the command:
```{r}
wordsAdded = as.data.frame(as.matrix(dtm))
colnames(wordsAdded) = paste("A", colnames(wordsAdded))  # for proper column names
```

Now repeat all of the steps we've done so far to create a Removed bag-of-words dataframe, called `wordsRemoved`, except this time, prepend all of the words with the letter R:

```{r}
# Create corpus
txt = iconv(wiki$Removed, to = "utf-8", sub="")
corpus = Corpus(VectorSource(txt))
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
dtm
nwRemoved = rowSums(as.matrix(dtm))
dtm = removeSparseTerms(dtm, 0.997)
dtm
wordsRemoved = as.data.frame(as.matrix(dtm))
colnames(wordsRemoved) = paste("R", colnames(wordsRemoved))
```
【P1.4】__How many words are in the `wordsRemoved` data frame?__

+ 162
+

##### 1.5 Prepare the Data Frame
Combine the Data Frames `wordsAdded` & `wordsRemoved` with the Target Variable `wiki$Vandal`
```{r}
wikiWords = cbind(wordsAdded, wordsRemoved)
wikiWords$Vandal = wiki$Vandal
```

Split the data frame for train and test data
```{r}
library(caTools)
set.seed(123)
spl = sample.split(wikiWords$Vandal, 0.7)
train = subset(wikiWords, spl == TRUE)
test = subset(wikiWords, spl == FALSE)
table(test$Vandal) %>% prop.table
```
【P1.5】__What is the accuracy on the test set of a baseline method that always predicts "not vandalism"?__

+ 0.53138
+

##### 1.6 CART Model
```{r}
library(rpart)
library(rpart.plot)
cart = rpart(Vandal~., train, method="class")
pred = predict(cart,test,type='class')
table(test$Vandal, pred) %>% {sum(diag(.)) / sum(.)} # 0.54428
```
【P1.6】__What is the accuracy of the model on the test set, using a threshold of 0.5?__

+ 0.54428
+


##### 1.7 Plot the Decision Tree
```{r fig.height=3.6}
prp(cart)
```
【P1.7】__How many word stems does the CART model use?__

+ 3
+

##### 1.8 Predictability of the CART model
【P1.8】__Given the performance of the CART model relative to the baseline, what is the best explanation of these results?__

+ Although it beats the baseline, bag of words is not very predictive for this problem.
+

<br><hr>

### Problem 2 - Add Features with Problem-specific Knowledge

##### 2.1 Add `HTTP` column
Add a new column based on whether `"http"` is added 
```{r}
wiki2 = wikiWords
wiki2$HTTP = ifelse( grepl("http",wiki$Added,fixed=TRUE) , 1, 0)
table(wiki2$HTTP) # 217
```
【P2.1】__Based on this new column, how many revisions added a link?__

+ 217
+

##### 2.2 Check accuracy again
```{r}
train2 = subset(wiki2, spl==T)
test2 = subset(wiki2, spl==F)
cart2 = rpart(Vandal~., train2, method="class")
pred2 = predict(cart2,test2,type='class')
table(test2$Vandal, pred2) %>% {sum(diag(.)) / sum(.)} # 0.57524
```
【P2.2】__What is the new accuracy of the CART model on the test set, using a threshold of 0.5?__

+ 0.57524
+

##### 2.3 Total numbers of words added and removed
```{r}
wiki2$nwAdded = nwAdded
wiki2$nwRemoved = nwRemoved
mean(nwAdded) # 4.0501
```
【P2.3】__What is the average number of words added?__

+ 4.0501
+

##### 2.4 Check accuracy again
```{r}
train = subset(wiki2, spl)
test = subset(wiki2, !spl)
cart = rpart(Vandal~., train, method="class")
pred = predict(cart,test,type='class')
table(test$Vandal, pred) %>% {sum(diag(.)) / sum(.)} # 0.6552
```
【P2.4】__What is the new accuracy of the CART model on the test set?__

+ 
+

<br><hr>

### Problem 3 - Using Non-Textual Data

原始資料之中還有一些之前沒有用到的欄位，我們把它們也加進來
```{r}
wiki3 = wiki2
wiki3$Minor = wiki$Minor
wiki3$Loggedin = wiki$Loggedin
```

##### 3.1 Check accuracy again
```{r}
train = subset(wiki3, spl=T)
test = subset(wiki3, spl=F)
cart = rpart(Vandal~., train, method="class")
pred = predict(cart,test,type='class')
table(test$Vandal, pred) %>% {sum(diag(.)) / sum(.)} # .72472
```
【P3.1】__What is the accuracy of the model on the test set?__

+ 0.72472
+

##### 3.2 The Decision Tree
```{r  fig.height=3.6}
prp(cart)
```

【P3.2】__How many splits are there in the tree?__

+ 3
+
  
<br><hr>

<p class="qiz">
討論議題：<br>
&emsp; ■ 請舉出一些可以繼續提高模型準確率的方法，方法越多越好： <br>
&emsp; &emsp; ●  <br>
&emsp; &emsp; ●  <br>
&emsp; &emsp; ●  <br>
&emsp; &emsp; ●  <br>
&emsp; &emsp; ●  <br>
<br>
</p>

<br><br><br><br>





